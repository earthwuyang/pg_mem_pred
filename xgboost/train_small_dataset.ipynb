{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_plans(file_path):\n",
    "    \"\"\"\n",
    "    Load parsed query plans from a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of parsed query plans.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        plans = json.load(f)\n",
    "    return plans\n",
    "\n",
    "# Load training and validation plans\n",
    "train_plans = load_plans('../tpch_data_20000/train_plans.json')\n",
    "val_plans = load_plans('../tpch_data_20000/val_plans.json')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training plans: 19531\n",
      "Number of validation plans: 4883\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training plans: {len(train_plans['parsed_plans'])}\")\n",
    "print(f\"Number of validation plans: {len(val_plans['parsed_plans'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "### Defining the Feature Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(parsed_plan):\n",
    "    \"\"\"\n",
    "    Extract features from a parsed PostgreSQL query plan.\n",
    "\n",
    "    Args:\n",
    "        parsed_plan (dict): The parsed query plan.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of aggregated features.\n",
    "    \"\"\"\n",
    "    features = defaultdict(float)\n",
    "    op_counts = defaultdict(int)\n",
    "    numerical_features = defaultdict(list)\n",
    "    max_depth = 0\n",
    "\n",
    "    def traverse(node, depth=1):\n",
    "        nonlocal max_depth\n",
    "        max_depth = max(max_depth, depth)\n",
    "\n",
    "        params = node.get('plan_parameters', {})\n",
    "        op_name = params.get('op_name', 'Unknown')\n",
    "        op_counts[op_name] += 1\n",
    "\n",
    "        # Collect numerical features\n",
    "        numerical_features['est_startup_cost'].append(params.get('est_startup_cost', 0.0))\n",
    "        numerical_features['est_cost'].append(params.get('est_cost', 0.0))\n",
    "        numerical_features['est_card'].append(params.get('est_card', 0.0))\n",
    "        numerical_features['est_width'].append(params.get('est_width', 0.0))\n",
    "        numerical_features['workers_planned'].append(params.get('workers_planned', 0.0))\n",
    "        numerical_features['est_children_card'].append(params.get('est_children_card', 0.0))\n",
    "\n",
    "        # Recursively traverse children\n",
    "        for child in node.get('children', []):\n",
    "            traverse(child, depth + 1)\n",
    "\n",
    "    traverse(parsed_plan)\n",
    "\n",
    "    # Aggregate operation counts\n",
    "    for op, count in op_counts.items():\n",
    "        features[f'op_count_{op}'] = count\n",
    "\n",
    "    # Aggregate numerical features\n",
    "    for feature, values in numerical_features.items():\n",
    "        features[f'{feature}_sum'] = sum(values)\n",
    "        features[f'{feature}_mean'] = np.mean(values) if values else 0.0\n",
    "        features[f'{feature}_max'] = max(values) if values else 0.0\n",
    "        features[f'{feature}_min'] = min(values) if values else 0.0\n",
    "\n",
    "    # Add structural features\n",
    "    features['tree_depth'] = max_depth\n",
    "    features['num_nodes'] = len(numerical_features['est_cost'])\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Feature Extraction to All Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19531/19531 [00:04<00:00, 4338.67it/s]\n",
      "100%|██████████| 4883/4883 [00:01<00:00, 4666.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (19531, 49)\n",
      "Validation features shape: (4883, 49)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def prepare_dataset(plans):\n",
    "    \"\"\"\n",
    "    Prepare a dataset by extracting features and collecting labels.\n",
    "\n",
    "    Args:\n",
    "        plans (list): A list of parsed query plans.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing features.\n",
    "        pd.Series: Series containing labels (peak memory).\n",
    "    \"\"\"\n",
    "    feature_dicts = []\n",
    "    labels = []\n",
    "\n",
    "    for plan in tqdm(plans['parsed_plans']):\n",
    "        features = extract_features(plan)\n",
    "        feature_dicts.append(features)\n",
    "        labels.append(plan.get('peakmem', 0.0))  # Assuming 'peakmem' is the target\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_features = pd.DataFrame(feature_dicts)\n",
    "    df_labels = pd.Series(labels, name='peakmem')\n",
    "\n",
    "    # Handle missing values if any\n",
    "    df_features.fillna(0, inplace=True)\n",
    "\n",
    "    # Encode categorical features (if any)\n",
    "    # Assuming 'op_count_*' are categorical; adjust based on actual data\n",
    "    op_count_features = [col for col in df_features.columns if col.startswith('op_count_')]\n",
    "    # If they are counts, you might treat them as numerical\n",
    "    # Otherwise, use label encoding or one-hot encoding as needed\n",
    "\n",
    "    # Feature scaling (optional)\n",
    "    scaler = StandardScaler()\n",
    "    numerical_cols = [col for col in df_features.columns if any(sub in col for sub in ['est_startup_cost', 'est_cost', 'est_card', 'est_width', 'workers_planned', 'est_children_card'])]\n",
    "    df_features[numerical_cols] = scaler.fit_transform(df_features[numerical_cols])\n",
    "\n",
    "    return df_features, df_labels\n",
    "\n",
    "# Prepare training and validation datasets\n",
    "X_train, y_train = prepare_dataset(train_plans)\n",
    "X_val, y_val = prepare_dataset(val_plans)\n",
    "X_val = X_val[X_train.columns]\n",
    "\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Validation features shape:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1, \n",
    "    colsample_bytree=0.8,\n",
    "    subsample=1.0\n",
    "\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "xgb_reg.save_model('xgb_model.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred = xgb_reg.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "# Plot feature importances\n",
    "xgb.plot_importance(xgb_reg, max_num_features=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qerror_min: 1.0001\n",
      "qerror_50 (Median): 1.5527\n",
      "qerror_90: 3.3221\n",
      "qerror_95: 3.8495\n",
      "qerror_99: 5.3618\n",
      "qerror_max: 9.2883\n",
      "mean_qerror: 1.9075\n",
      "mae: 29857.5746\n",
      "mre: 0.8314\n",
      "mse: 1368683570.4896\n",
      "r2: 0.6025\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import metrics\n",
    "import importlib\n",
    "importlib.reload(metrics)\n",
    "metrics_dict = metrics.compute_metrics(y_val, y_pred)\n",
    "for metric, value in metrics_dict.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53607/53607 [00:11<00:00, 4513.38it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['op_count_Aggregate', 'op_count_Seq Scan', 'est_startup_cost_sum', 'est_startup_cost_mean', 'est_startup_cost_max', 'est_startup_cost_min', 'est_cost_sum', 'est_cost_mean', 'est_cost_max', 'est_cost_min', 'est_card_sum', 'est_card_mean', 'est_card_max', 'est_card_min', 'est_width_sum', 'est_width_mean', 'est_width_max', 'est_width_min', 'workers_planned_sum', 'workers_planned_mean', 'workers_planned_max', 'workers_planned_min', 'est_children_card_sum', 'est_children_card_mean', 'est_children_card_max', 'est_children_card_min', 'tree_depth', 'num_nodes', 'op_count_Finalize Aggregate', 'op_count_Gather', 'op_count_Partial Aggregate', 'op_count_Hash Join', 'op_count_Parallel Seq Scan', 'op_count_Hash', 'op_count_Nested Loop', 'op_count_Bitmap Heap Scan', 'op_count_Bitmap Index Scan', 'op_count_Index Scan', 'op_count_Index Only Scan', 'op_count_Parallel Bitmap Heap Scan', 'op_count_Parallel Hash Join', 'op_count_Parallel Hash', 'op_count_Parallel Index Only Scan', 'op_count_Parallel Index Scan', 'op_count_Merge Join', 'op_count_Sort', 'op_count_BitmapAnd', 'op_count_Materialize', 'op_count_Memoize'] ['op_count_Aggregate', 'op_count_Merge Join', 'op_count_Nested Loop', 'op_count_Index Scan', 'op_count_Materialize', 'op_count_Gather', 'op_count_Parallel Seq Scan', 'op_count_Sort', 'op_count_Seq Scan', 'est_startup_cost_sum', 'est_startup_cost_mean', 'est_startup_cost_max', 'est_startup_cost_min', 'est_cost_sum', 'est_cost_mean', 'est_cost_max', 'est_cost_min', 'est_card_sum', 'est_card_mean', 'est_card_max', 'est_card_min', 'est_width_sum', 'est_width_mean', 'est_width_max', 'est_width_min', 'workers_planned_sum', 'workers_planned_mean', 'workers_planned_max', 'workers_planned_min', 'est_children_card_sum', 'est_children_card_mean', 'est_children_card_max', 'est_children_card_min', 'tree_depth', 'num_nodes', 'op_count_Finalize Aggregate', 'op_count_Partial Aggregate', 'op_count_Parallel Hash Join', 'op_count_Hash Join', 'op_count_Hash', 'op_count_Parallel Hash', 'op_count_Memoize', 'op_count_Parallel Bitmap Heap Scan', 'op_count_Bitmap Index Scan', 'op_count_Parallel Index Only Scan', 'op_count_Index Only Scan', 'op_count_Bitmap Heap Scan', 'op_count_BitmapAnd', 'op_count_Parallel Index Scan', 'op_count_Gather Merge']\ntraining data did not have the following fields: op_count_Gather Merge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m val_plans \u001b[38;5;241m=\u001b[39m load_plans(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../tpcds_data/val_plans.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m prepare_dataset(train_plans)\n\u001b[0;32m---> 20\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m \u001b[43mxgb_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the validation set\u001b[39;00m\n\u001b[1;32m     22\u001b[0m metrics_dict \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mcompute_metrics(y_test, y_test_pred)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/sklearn.py:1186\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1186\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[1;32m   1195\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m~/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:2522\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2520\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[0;32m-> 2522\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[1;32m   2524\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:3087\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[0;34m(self, feature_names)\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[1;32m   3082\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3083\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3084\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[1;32m   3085\u001b[0m     )\n\u001b[0;32m-> 3087\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['op_count_Aggregate', 'op_count_Seq Scan', 'est_startup_cost_sum', 'est_startup_cost_mean', 'est_startup_cost_max', 'est_startup_cost_min', 'est_cost_sum', 'est_cost_mean', 'est_cost_max', 'est_cost_min', 'est_card_sum', 'est_card_mean', 'est_card_max', 'est_card_min', 'est_width_sum', 'est_width_mean', 'est_width_max', 'est_width_min', 'workers_planned_sum', 'workers_planned_mean', 'workers_planned_max', 'workers_planned_min', 'est_children_card_sum', 'est_children_card_mean', 'est_children_card_max', 'est_children_card_min', 'tree_depth', 'num_nodes', 'op_count_Finalize Aggregate', 'op_count_Gather', 'op_count_Partial Aggregate', 'op_count_Hash Join', 'op_count_Parallel Seq Scan', 'op_count_Hash', 'op_count_Nested Loop', 'op_count_Bitmap Heap Scan', 'op_count_Bitmap Index Scan', 'op_count_Index Scan', 'op_count_Index Only Scan', 'op_count_Parallel Bitmap Heap Scan', 'op_count_Parallel Hash Join', 'op_count_Parallel Hash', 'op_count_Parallel Index Only Scan', 'op_count_Parallel Index Scan', 'op_count_Merge Join', 'op_count_Sort', 'op_count_BitmapAnd', 'op_count_Materialize', 'op_count_Memoize'] ['op_count_Aggregate', 'op_count_Merge Join', 'op_count_Nested Loop', 'op_count_Index Scan', 'op_count_Materialize', 'op_count_Gather', 'op_count_Parallel Seq Scan', 'op_count_Sort', 'op_count_Seq Scan', 'est_startup_cost_sum', 'est_startup_cost_mean', 'est_startup_cost_max', 'est_startup_cost_min', 'est_cost_sum', 'est_cost_mean', 'est_cost_max', 'est_cost_min', 'est_card_sum', 'est_card_mean', 'est_card_max', 'est_card_min', 'est_width_sum', 'est_width_mean', 'est_width_max', 'est_width_min', 'workers_planned_sum', 'workers_planned_mean', 'workers_planned_max', 'workers_planned_min', 'est_children_card_sum', 'est_children_card_mean', 'est_children_card_max', 'est_children_card_min', 'tree_depth', 'num_nodes', 'op_count_Finalize Aggregate', 'op_count_Partial Aggregate', 'op_count_Parallel Hash Join', 'op_count_Hash Join', 'op_count_Hash', 'op_count_Parallel Hash', 'op_count_Memoize', 'op_count_Parallel Bitmap Heap Scan', 'op_count_Bitmap Index Scan', 'op_count_Parallel Index Only Scan', 'op_count_Index Only Scan', 'op_count_Bitmap Heap Scan', 'op_count_BitmapAnd', 'op_count_Parallel Index Scan', 'op_count_Gather Merge']\ntraining data did not have the following fields: op_count_Gather Merge"
     ]
    }
   ],
   "source": [
    "def load_plans(file_path):\n",
    "    \"\"\"\n",
    "    Load parsed query plans from a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of parsed query plans.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        plans = json.load(f)\n",
    "    return plans\n",
    "\n",
    "# Load training and validation plans\n",
    "train_plans = load_plans('../tpcds_data/train_plans.json')\n",
    "val_plans = load_plans('../tpcds_data/val_plans.json')\n",
    "\n",
    "X_test, y_test = prepare_dataset(train_plans)\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "extra_cols = set(X_test.columns) - set(X_train.columns)\n",
    "for col in missing_cols:\n",
    "    X_test[col] = 0\n",
    "# X_test.drop(extra_cols, inplace=True)\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qerror_min: 1.0000\n",
      "qerror_50 (Median): 2.7522\n",
      "qerror_90: 7.3695\n",
      "qerror_95: 8.4042\n",
      "qerror_99: 10.0122\n",
      "qerror_max: 22.8185\n",
      "mean_qerror: 3.5936\n",
      "mae: 61060.4266\n",
      "mre: 2.5702\n",
      "mse: 4962975070.3537\n",
      "r2: -2.8182\n"
     ]
    }
   ],
   "source": [
    "import metrics\n",
    "y_test_pred = xgb_reg.predict(X_test)\n",
    "# Evaluate the model on the validation set\n",
    "metrics_dict = metrics.compute_metrics(y_test, y_test_pred)\n",
    "for metric, value in metrics_dict.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.8; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.8; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.8; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=1.0; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=1.0; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=1.0; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=  13.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=  13.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=  14.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=  16.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=  17.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.8; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.8; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.8; total time=  18.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.8; total time=  21.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0; total time=  22.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0; total time=  22.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0; total time=  22.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.8; total time=  23.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=200, subsample=0.8; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=200, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=200, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=200, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=200, subsample=0.8; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.8; total time=  13.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.8; total time=  14.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=200, subsample=1.0; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.8; total time=  15.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0; total time=  15.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=300, subsample=1.0; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=300, subsample=0.8; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=300, subsample=1.0; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0; total time=  15.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0; total time=  16.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=300, subsample=1.0; total time=   8.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=300, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=300, subsample=0.8; total time=   9.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   8.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   9.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.8; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.8; total time=  14.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.8; total time=  14.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.8; total time=  14.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.8; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.8; total time=   7.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   7.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   7.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=0.8; total time=   8.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=200, subsample=1.0; total time=   8.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   7.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   7.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=0.8; total time=   8.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, subsample=1.0; total time=   8.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=  11.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=  11.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=1.0; total time=  11.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=1.0; total time=  11.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=1.0; total time=  12.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=300, subsample=0.8; total time=  13.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=  15.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=  16.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.8; total time=  16.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.8; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=0.8; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=  17.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=  17.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=200, subsample=1.0; total time=   7.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=1.0; total time=  19.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0; total time=   7.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0; total time=   8.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   6.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   9.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   9.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=1.0; total time=   9.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   6.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=  11.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.8; total time=  23.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0; total time=  23.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.8; total time=  24.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0; total time=  23.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.8; total time=  25.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=  11.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=  11.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=  10.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=1.0; total time=  10.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=  13.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=  13.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.8; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=0.8; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=300, subsample=1.0; total time=  29.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=6, n_estimators=300, subsample=1.0; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=200, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=200, subsample=0.8; total time=   6.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0; total time=  14.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=200, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=200, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0; total time=  14.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=200, subsample=1.0; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=200, subsample=0.8; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=1.0; total time=  15.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.8; total time=  16.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   6.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   6.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   6.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.8; total time=  17.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.8; total time=  17.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.8; total time=   6.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=300, subsample=1.0; total time=   7.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=300, subsample=1.0; total time=   7.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=300, subsample=1.0; total time=   8.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=300, subsample=0.8; total time=   8.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=300, subsample=0.8; total time=   8.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=8, n_estimators=300, subsample=0.8; total time=   8.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   6.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=1.0; total time=   6.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   7.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   8.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.8; total time=   9.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0; total time=   8.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.8; total time=   9.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.8; total time=  10.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=1.0; total time=   8.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=10, n_estimators=300, subsample=0.8; total time=  10.8s\n",
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Best CV Score (Negative MSE): -807305187.9564403\n",
      "\n",
      "Validation Metrics for Best Model:\n",
      "qerror_min: 1.0001\n",
      "qerror_50 (Median): 1.5457\n",
      "qerror_90: 2.6849\n",
      "qerror_95: 3.0288\n",
      "qerror_99: 4.7642\n",
      "qerror_max: 9.0451\n",
      "mean_qerror: 1.7577\n",
      "mae: 27608.1172\n",
      "mre: 0.6767\n",
      "mse: 1257741297.4863\n",
      "r2: 0.6347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_reg = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_reg,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV Score (Negative MSE): {grid_search.best_score_}\")\n",
    "\n",
    "# Use the best estimator for predictions\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred_best = best_xgb.predict(X_val)\n",
    "\n",
    "# Compute metrics for the best model\n",
    "metrics_best = metrics.compute_metrics(y_val, y_pred_best)\n",
    "\n",
    "print(\"\\nValidation Metrics for Best Model:\")\n",
    "for metric, value in metrics_best.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_val, \u001b[43my_pred_best\u001b[49m)\n\u001b[1;32m      3\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_val, y_pred_best)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_best' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "mse = mean_squared_error(y_val, y_pred_best)\n",
    "r2 = r2_score(y_val, y_pred_best)\n",
    "\n",
    "print(f\"Test MSE: {mse:.2f}\")\n",
    "print(f\"Test R² Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb.save_model('xgb_model_small_tpch_best_model.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zsce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
