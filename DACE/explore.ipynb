{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuy/software/anaconda3/envs/dace/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from utils import *\n",
    "from plan_utils import *\n",
    "\n",
    "with open('/home/wuy/DB/pg_mem_data/tpch/tiny_plans.json') as f:\n",
    "    plans = json.load(f)\n",
    "\n",
    "plan = plans[0]\n",
    "plan['database_id']=0\n",
    "plan['plan_id']=0\n",
    "\n",
    "statistics_file = '/home/wuy/DB/DACE/data/workload1/statistics.json'\n",
    "feature_statistics = load_json(statistics_file)\n",
    "add_numerical_scalers(feature_statistics)\n",
    "op_name_to_one_hot = get_op_name_to_one_hot(feature_statistics)\n",
    "\n",
    "configs = {\"pad_length\":20, \"max_runtime\":30000, \"node_length\":18, \"loss_weight\":0.5, \"hidden_dim\": 128,\n",
    "           \"mlp_activation\": \"ReLU\", \"transformer_activation\": \"gelu\", \"mlp_dropout\": 0.3, \"transformer_dropout\": 0.2}\n",
    "plan_meta = get_plan_encoding(plan, configs, op_name_to_one_hot, plan_parameters, feature_statistics)\n",
    "# print(plan_meta)  # seq_encoding, run_times, attention_mask, loss_mask, database_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "seq, run_time, attention_mask, loss_mask = plan_meta[:-1]\n",
    "dataset = DACEDataset([seq], [attention_mask], [loss_mask], [run_time]) # return seq, attn_mask, loss_mask, run_time\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DACELora, PL_DACE\n",
    "model = DACELora(\n",
    "    configs[\"node_length\"],\n",
    "    configs[\"hidden_dim\"],\n",
    "    1,\n",
    "    configs[\"mlp_activation\"],\n",
    "    configs[\"transformer_activation\"],\n",
    "    configs[\"mlp_dropout\"],\n",
    "    configs[\"transformer_dropout\"],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DACE Loss\n",
    "def DACE_loss(est_run_times, run_times, loss_mask, loss_fn):\n",
    "    # est_run_times: (batch, seq_len)\n",
    "    # run_times: (batch, seq_len)\n",
    "    # loss_mask: (batch, seq_len)\n",
    "    # return: loss (batch,)\n",
    "    # don't calculate the loss of padding nodes, set them to 0\n",
    "    # loss = torch.max(est_run_times / run_times, run_times / est_run_times)\n",
    "    loss = loss_fn(est_run_times[0], run_times[0])\n",
    "    print(f\"loss {loss}\")\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.20530235767364502\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "model.train()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "for data in dataloader:\n",
    "    seqs, attn_masks, loss_masks, run_times = data\n",
    "    est_run_times = model(seqs, attn_masks)\n",
    "    loss = DACE_loss(est_run_times, run_times, loss_masks, loss_fn)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_run_times.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
