{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_plan(plan, parent=None, nodes=None, edges=None, node_id=0):\n",
    "    \"\"\"\n",
    "    Recursively parse the JSON plan and build node features and edges.\n",
    "    \n",
    "    Args:\n",
    "        plan (dict): The JSON plan.\n",
    "        parent (int): The parent node ID.\n",
    "        nodes (list): List to store node features.\n",
    "        edges (list): List to store edge connections.\n",
    "        node_id (int): Unique identifier for nodes.\n",
    "        \n",
    "    Returns:\n",
    "        node_id (int): Updated node ID.\n",
    "    \"\"\"\n",
    "    if nodes is None:\n",
    "        nodes = []\n",
    "    if edges is None:\n",
    "        edges = []\n",
    "        \n",
    "    current_id = node_id\n",
    "    # print(f\"plan: {plan}\")\n",
    "    if 'Plan' in plan:\n",
    "        plan_node = plan['Plan']\n",
    "    else: \n",
    "        plan_node = plan\n",
    "    \n",
    "    # Extract features from the current node\n",
    "    features = extract_features(plan_node)\n",
    "    nodes.append(features)\n",
    "    \n",
    "    # If there is a parent, add an edge\n",
    "    if parent is not None:\n",
    "        edges.append([parent, current_id])\n",
    "    \n",
    "    # Initialize children if not present\n",
    "    children = plan_node.get('Plans', [])\n",
    "    \n",
    "    # Recursively parse children\n",
    "    for child in children:\n",
    "        node_id += 1\n",
    "        node_id = parse_plan(child, parent=current_id, nodes=nodes, edges=edges, node_id=node_id)\n",
    "    \n",
    "    return node_id\n",
    "\n",
    "def extract_features(plan_node):\n",
    "    \"\"\"\n",
    "    Extract relevant features from a plan node.\n",
    "    \n",
    "    Args:\n",
    "        plan_node (dict): A single plan node from the JSON.\n",
    "        \n",
    "    Returns:\n",
    "        feature_vector (list): A list of numerical features.\n",
    "    \"\"\"\n",
    "    # Define which features to extract\n",
    "    feature_vector = []\n",
    "    \n",
    "    # Numerical features\n",
    "    numerical_features = [\n",
    "        plan_node.get('Startup Cost', 0.0),\n",
    "        plan_node.get('Total Cost', 0.0),\n",
    "        plan_node.get('Plan Rows', 0.0),\n",
    "        plan_node.get('Plan Width', 0.0),\n",
    "        plan_node.get('Workers Planned', 0.0)\n",
    "    ]\n",
    "    feature_vector.extend(numerical_features)\n",
    "    \n",
    "    # Categorical features: Node Type, Join Type, etc.\n",
    "    categorical_features = [\n",
    "        plan_node.get('Node Type', ''),\n",
    "        plan_node.get('Join Type', ''),\n",
    "        plan_node.get('Strategy', ''),\n",
    "        plan_node.get('Partial Mode', ''),\n",
    "        plan_node.get('Parent Relationship', ''),\n",
    "        plan_node.get('Scan Direction', ''),\n",
    "        plan_node.get('Filter', ''),\n",
    "        plan_node.get('Hash Cond', ''),\n",
    "        plan_node.get('Index Cond', ''),\n",
    "        plan_node.get('Join Filter', '')\n",
    "    ]\n",
    "    \n",
    "    # Convert categorical features to numerical via one-hot encoding or other encoding schemes\n",
    "    # For simplicity, we'll use a basic encoding: assign a unique integer to each category\n",
    "    # In practice, you might want to use more sophisticated encoding methods\n",
    "    categorical_dict = {\n",
    "        'Node Type': {},\n",
    "        'Join Type': {},\n",
    "        'Strategy': {},\n",
    "        'Partial Mode': {},\n",
    "        'Parent Relationship': {},\n",
    "        'Scan Direction': {},\n",
    "        'Filter': {},\n",
    "        'Hash Cond': {},\n",
    "        'Index Cond': {},\n",
    "        'Join Filter': {}\n",
    "    }\n",
    "    \n",
    "    # This dictionary should be built based on your dataset to map categories to integers\n",
    "    # For demonstration, we'll assign arbitrary integers\n",
    "    # You should replace this with a consistent encoding based on your dataset\n",
    "    for i, cat in enumerate(categorical_features):\n",
    "        if cat not in categorical_dict[list(categorical_dict.keys())[i]]:\n",
    "            categorical_dict[list(categorical_dict.keys())[i]][cat] = len(categorical_dict[list(categorical_dict.keys())[i]])\n",
    "        feature_vector.append(categorical_dict[list(categorical_dict.keys())[i]][cat])\n",
    "    \n",
    "    return feature_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanGraphDataset(Dataset):\n",
    "    def __init__(self, json_plans, transform=None, pre_transform=None):\n",
    "        super(PlanGraphDataset, self).__init__(None, transform, pre_transform)\n",
    "        self.json_plans = json_plans\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.json_plans)\n",
    "\n",
    "    def get(self, idx):\n",
    "        plan = self.json_plans[idx]\n",
    "        \n",
    "        # Parse the plan into nodes and edges\n",
    "        nodes = []\n",
    "        edges = []\n",
    "        parse_plan(plan, nodes=nodes, edges=edges)\n",
    "        \n",
    "        # Convert lists to tensors\n",
    "        x = torch.tensor(nodes, dtype=torch.float)\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        \n",
    "        # Apply scaling to features\n",
    "        x = torch.tensor(self.scaler.fit_transform(x.numpy()), dtype=torch.float)\n",
    "        \n",
    "        # Get the label (peakmem)\n",
    "        y = torch.tensor(plan.get('peakmem', 0.0), dtype=torch.float)\n",
    "        \n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_plans(file_path):\n",
    "    \"\"\"\n",
    "    Load the JSON execution plans from a file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file containing execution plans.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of execution plan dictionaries.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        plans = json.load(f)\n",
    "    return plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'plans.json' contains a list of execution plans like the one provided\n",
    "json_plans = load_plans('../tpch_data/explain_json_plans.json')  # Replace with your actual file path\n",
    "# json_plans = None\n",
    "\n",
    "# Create the dataset\n",
    "dataset = PlanGraphDataset(json_plans)\n",
    "\n",
    "# Split into training and testing sets (e.g., 80% train, 20% test)\n",
    "train_size = int(0.5 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10240\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.fc = torch.nn.Linear(hidden_channels, 1)  # Regression output\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # First Graph Convolutional layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "\n",
    "        # Second Graph Convolutional layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "\n",
    "        # Global mean pooling\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # Final linear layer\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x.squeeze()  # [batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(15, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 10305668320.1328, Test Loss: 10187757859.8474\n",
      "Test Metrics: {'qerror_50 (Median)': 384.1461181640625, 'qerror_95': 951.884716796875, 'qerror_max': 1094.7191162109375, 'mean_qerror': 447.91696, 'mre': 0.9947604, 'rmse': 103873.266}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Loss: 10240906709.5214, Test Loss: 9973128812.9727\n",
      "Test Metrics: {'qerror_50 (Median)': 48.8687858581543, 'qerror_95': 120.77164382934569, 'qerror_max': 139.7330322265625, 'mean_qerror': 57.271336, 'mre': 0.95916677, 'rmse': 102798.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Loss: 9935218592.9054, Test Loss: 9336083569.7959\n",
      "Test Metrics: {'qerror_50 (Median)': 13.342840194702148, 'qerror_95': 32.64859619140625, 'qerror_max': 37.839202880859375, 'mean_qerror': 15.537556, 'mre': 0.849844, 'rmse': 99532.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Loss: 9133072649.3688, Test Loss: 8025446484.6112\n",
      "Test Metrics: {'qerror_50 (Median)': 5.0608954429626465, 'qerror_95': 12.304132270812987, 'qerror_max': 14.255942344665527, 'mean_qerror': 5.895074, 'mre': 0.63964856, 'rmse': 92415.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Loss: 7619520007.7828, Test Loss: 6023708384.8124\n",
      "Test Metrics: {'qerror_50 (Median)': 2.6005427837371826, 'qerror_95': 5.602666807174682, 'qerror_max': 6.491188049316406, 'mean_qerror': 3.1210904, 'mre': 0.7424967, 'rmse': 80158.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Train Loss: 5526079259.2563, Test Loss: 4169771838.7431\n",
      "Test Metrics: {'qerror_50 (Median)': 2.4609107971191406, 'qerror_95': 4.79549832344055, 'qerror_max': 6.668886184692383, 'mean_qerror': 2.6006258, 'mre': 1.2130541, 'rmse': 66043.234}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Train Loss: 4056822051.8567, Test Loss: 4379313300.7032\n",
      "Test Metrics: {'qerror_50 (Median)': 1.8249530792236328, 'qerror_95': 7.435440587997434, 'qerror_max': 10.357765197753906, 'mean_qerror': 2.99501, 'mre': 1.8997046, 'rmse': 65534.992}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Train Loss: 4546229465.7888, Test Loss: 4437348125.6344\n",
      "Test Metrics: {'qerror_50 (Median)': 1.7428327798843384, 'qerror_95': 7.5619686126708965, 'qerror_max': 10.335967063903809, 'mean_qerror': 3.0334914, 'mre': 1.9598204, 'rmse': 65733.016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Train Loss: 4210586621.9562, Test Loss: 3666064115.2470\n",
      "Test Metrics: {'qerror_50 (Median)': 1.9242764711380005, 'qerror_95': 6.0874859333038325, 'qerror_max': 7.95972204208374, 'mean_qerror': 2.7062366, 'mre': 1.560336, 'rmse': 60777.855}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Loss: 3615400829.8990, Test Loss: 3528754498.7080\n",
      "Test Metrics: {'qerror_50 (Median)': 2.1074469089508057, 'qerror_95': 4.864984321594238, 'qerror_max': 6.297646522521973, 'mean_qerror': 2.497308, 'mre': 1.254534, 'rmse': 60524.996}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Train Loss: 3540272384.3761, Test Loss: 3432981462.3484\n",
      "Test Metrics: {'qerror_50 (Median)': 2.103628635406494, 'qerror_95': 4.459434080123901, 'qerror_max': 5.6776251792907715, 'mean_qerror': 2.4196196, 'mre': 1.1609908, 'rmse': 59907.023}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Train Loss: 3389290370.5098, Test Loss: 3158412555.9764\n",
      "Test Metrics: {'qerror_50 (Median)': 1.9834539890289307, 'qerror_95': 4.728691053390501, 'qerror_max': 5.949492931365967, 'mean_qerror': 2.4145958, 'mre': 1.2238663, 'rmse': 57220.332}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Train Loss: 3107034778.1690, Test Loss: 2969104870.3305\n",
      "Test Metrics: {'qerror_50 (Median)': 1.8293206691741943, 'qerror_95': 5.316422605514525, 'qerror_max': 6.603728294372559, 'mean_qerror': 2.4744675, 'mre': 1.3572803, 'rmse': 54981.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Train Loss: 2960867020.3978, Test Loss: 2910369851.1870\n",
      "Test Metrics: {'qerror_50 (Median)': 1.725146770477295, 'qerror_95': 5.5862040519714355, 'qerror_max': 7.158000469207764, 'mean_qerror': 2.510629, 'mre': 1.4279851, 'rmse': 54142.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Train Loss: 2884830864.7838, Test Loss: 2761357795.1423\n",
      "Test Metrics: {'qerror_50 (Median)': 1.7366803884506226, 'qerror_95': 5.345050716400146, 'qerror_max': 7.079533576965332, 'mean_qerror': 2.4380527, 'mre': 1.3509558, 'rmse': 52932.707}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Train Loss: 2726250179.5521, Test Loss: 2629108262.7086\n",
      "Test Metrics: {'qerror_50 (Median)': 1.7974101305007935, 'qerror_95': 4.948388624191283, 'qerror_max': 6.705875873565674, 'mean_qerror': 2.3314612, 'mre': 1.2229272, 'rmse': 52006.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Train Loss: 2614146136.3582, Test Loss: 2553137974.8133\n",
      "Test Metrics: {'qerror_50 (Median)': 1.8124014139175415, 'qerror_95': 4.789305305480957, 'qerror_max': 6.5696330070495605, 'mean_qerror': 2.2783358, 'mre': 1.1631154, 'rmse': 51403.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Train Loss: 2541474864.1359, Test Loss: 2484457686.7163\n",
      "Test Metrics: {'qerror_50 (Median)': 1.7925457954406738, 'qerror_95': 4.827191019058227, 'qerror_max': 6.640063762664795, 'mean_qerror': 2.26164, 'mre': 1.1540555, 'rmse': 50713.656}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Train Loss: 2473696128.8911, Test Loss: 2431762122.3720\n",
      "Test Metrics: {'qerror_50 (Median)': 1.7292736768722534, 'qerror_95': 4.96188998222351, 'qerror_max': 6.8135786056518555, 'mean_qerror': 2.2617397, 'mre': 1.1664532, 'rmse': 50117.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Train Loss: 2424965968.3955, Test Loss: 2392672127.1212\n",
      "Test Metrics: {'qerror_50 (Median)': 1.7056349515914917, 'qerror_95': 5.043019485473631, 'qerror_max': 6.904600620269775, 'mean_qerror': 2.248731, 'mre': 1.1581621, 'rmse': 49704.773}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 021, Train Loss: 2385473488.0930, Test Loss: 2355813233.1011\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6989942789077759, 'qerror_95': 4.961092329025268, 'qerror_max': 6.857601642608643, 'mean_qerror': 2.215371, 'mre': 1.1201274, 'rmse': 49381.637}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 022, Train Loss: 2350141156.1878, Test Loss: 2328276336.8149\n",
      "Test Metrics: {'qerror_50 (Median)': 1.677025318145752, 'qerror_95': 4.882285022735595, 'qerror_max': 6.75813627243042, 'mean_qerror': 2.1851919, 'mre': 1.0836679, 'rmse': 49165.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023, Train Loss: 2323848534.9357, Test Loss: 2305085827.6992\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6801671981811523, 'qerror_95': 4.8673668384552, 'qerror_max': 6.720885276794434, 'mean_qerror': 2.1729198, 'mre': 1.0713835, 'rmse': 48949.195}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024, Train Loss: 2300619692.4162, Test Loss: 2285143450.8344\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6609553098678589, 'qerror_95': 4.899917936325071, 'qerror_max': 6.71528434753418, 'mean_qerror': 2.1689885, 'mre': 1.0707283, 'rmse': 48741.688}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025, Train Loss: 2281279380.4136, Test Loss: 2268881074.4602\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6495904922485352, 'qerror_95': 4.90852551460266, 'qerror_max': 6.746968746185303, 'mean_qerror': 2.164042, 'mre': 1.0677229, 'rmse': 48581.523}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 026, Train Loss: 2265478540.8760, Test Loss: 2255439927.5900\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6349661350250244, 'qerror_95': 4.954404544830322, 'qerror_max': 6.795635223388672, 'mean_qerror': 2.1593258, 'mre': 1.0639715, 'rmse': 48459.434}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 027, Train Loss: 2252197837.3788, Test Loss: 2243470587.4220\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6400059461593628, 'qerror_95': 4.9485201835632315, 'qerror_max': 6.790045738220215, 'mean_qerror': 2.1503036, 'mre': 1.0531802, 'rmse': 48368.137}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 028, Train Loss: 2240577998.6541, Test Loss: 2233215986.1434\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6397157907485962, 'qerror_95': 4.944987630844115, 'qerror_max': 6.773052215576172, 'mean_qerror': 2.14202, 'mre': 1.0429848, 'rmse': 48293.266}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 029, Train Loss: 2230744131.7075, Test Loss: 2224779511.5798\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6398653984069824, 'qerror_95': 4.979297733306884, 'qerror_max': 6.781121253967285, 'mean_qerror': 2.1386616, 'mre': 1.0393993, 'rmse': 48223.434}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 030, Train Loss: 2222655970.5445, Test Loss: 2217808223.3205\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6241233348846436, 'qerror_95': 5.020627212524414, 'qerror_max': 6.790483474731445, 'mean_qerror': 2.1378984, 'mre': 1.0386765, 'rmse': 48168.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:12<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 031, Train Loss: 2215732033.4756, Test Loss: 2210889289.8202\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6246237754821777, 'qerror_95': 5.064113664627075, 'qerror_max': 6.787137508392334, 'mean_qerror': 2.1364422, 'mre': 1.0366759, 'rmse': 48124.168}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 032, Train Loss: 2209033782.1202, Test Loss: 2205107847.5823\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6133604049682617, 'qerror_95': 5.113655662536619, 'qerror_max': 6.824342250823975, 'mean_qerror': 2.1393576, 'mre': 1.0418937, 'rmse': 48081.836}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 033, Train Loss: 2203069913.7234, Test Loss: 2198533119.7956\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6178827285766602, 'qerror_95': 5.1122629642486555, 'qerror_max': 6.760957717895508, 'mean_qerror': 2.1322088, 'mre': 1.0311478, 'rmse': 48060.254}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Train Loss: 2197272760.8426, Test Loss: 2193840309.6484\n",
      "Test Metrics: {'qerror_50 (Median)': 1.622084140777588, 'qerror_95': 5.103263187408445, 'qerror_max': 6.679586887359619, 'mean_qerror': 2.1241407, 'mre': 1.0189112, 'rmse': 48062.496}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 035, Train Loss: 2192631439.1161, Test Loss: 2188870395.5038\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6085295677185059, 'qerror_95': 5.170507097244263, 'qerror_max': 6.728682041168213, 'mean_qerror': 2.1292784, 'mre': 1.028372, 'rmse': 48020.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 036, Train Loss: 2187979291.3054, Test Loss: 2184316946.7616\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6034055948257446, 'qerror_95': 5.149659824371336, 'qerror_max': 6.716464996337891, 'mean_qerror': 2.1286814, 'mre': 1.0282552, 'rmse': 47994.598}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 037, Train Loss: 2183150522.8210, Test Loss: 2180373434.6352\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6157290935516357, 'qerror_95': 5.04962129592895, 'qerror_max': 6.605142116546631, 'mean_qerror': 2.1179733, 'mre': 1.011704, 'rmse': 47995.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 038, Train Loss: 2180233586.0612, Test Loss: 2176272273.6784\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6115738153457642, 'qerror_95': 5.088604164123532, 'qerror_max': 6.578969955444336, 'mean_qerror': 2.1168654, 'mre': 1.0107065, 'rmse': 47975.062}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 039, Train Loss: 2175500868.3288, Test Loss: 2172039616.2350\n",
      "Test Metrics: {'qerror_50 (Median)': 1.5965214967727661, 'qerror_95': 5.068071603775017, 'qerror_max': 6.639473915100098, 'mean_qerror': 2.126474, 'mre': 1.0262223, 'rmse': 47935.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 040, Train Loss: 2171078638.3414, Test Loss: 2167216531.3952\n",
      "Test Metrics: {'qerror_50 (Median)': 1.6030610799789429, 'qerror_95': 5.112547254562377, 'qerror_max': 6.529017448425293, 'mean_qerror': 2.1177785, 'mre': 1.0126773, 'rmse': 47939.168}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 041, Train Loss: 2167589138.2390, Test Loss: 2163649280.1226\n",
      "Test Metrics: {'qerror_50 (Median)': 1.615297555923462, 'qerror_95': 5.065478277206419, 'qerror_max': 6.492865562438965, 'mean_qerror': 2.111551, 'mre': 1.0030191, 'rmse': 47944.164}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.91s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m train()\n\u001b[1;32m     44\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m---> 45\u001b[0m test_loss, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Metrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[27], line 32\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     30\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     33\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     34\u001b[0m         out \u001b[38;5;241m=\u001b[39m model(data)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/zsce/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/software/anaconda3/envs/zsce/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1330\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1330\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1333\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/software/anaconda3/envs/zsce/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1296\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1296\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1298\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/software/anaconda3/envs/zsce/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1134\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/software/anaconda3/envs/zsce/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/software/anaconda3/envs/zsce/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/software/anaconda3/envs/zsce/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/zsce/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/software/anaconda3/envs/zsce/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss, and optimizer\n",
    "num_node_features = len(dataset[0].x[0])  # Number of features per node\n",
    "hidden_channels = 64\n",
    "model = GCN(num_node_features, hidden_channels)\n",
    "print(model)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "from tqdm import tqdm\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in tqdm(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "from metrics import compute_metrics\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            loss = criterion(out, data.y)\n",
    "            metrics = compute_metrics(data.y.cpu().numpy(), out.detach().cpu().numpy())\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset), metrics\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    train_loss = loss\n",
    "    test_loss, metrics = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "    print(f\"Test Metrics: {metrics}\")\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), f'model_{epoch}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Plan\": {\n",
      "    \"Node Type\": \"Aggregate\",\n",
      "    \"Strategy\": \"Plain\",\n",
      "    \"Partial Mode\": \"Finalize\",\n",
      "    \"Parallel Aware\": false,\n",
      "    \"Async Capable\": false,\n",
      "    \"Startup Cost\": 160309.37,\n",
      "    \"Total Cost\": 160309.38,\n",
      "    \"Plan Rows\": 1,\n",
      "    \"Plan Width\": 8,\n",
      "    \"Plans\": [\n",
      "      {\n",
      "        \"Node Type\": \"Gather\",\n",
      "        \"Parent Relationship\": \"Outer\",\n",
      "        \"Parallel Aware\": false,\n",
      "        \"Async Capable\": false,\n",
      "        \"Startup Cost\": 160309.15,\n",
      "        \"Total Cost\": 160309.36,\n",
      "        \"Plan Rows\": 2,\n",
      "        \"Plan Width\": 8,\n",
      "        \"Workers Planned\": 2,\n",
      "        \"Single Copy\": false,\n",
      "        \"Plans\": [\n",
      "          {\n",
      "            \"Node Type\": \"Aggregate\",\n",
      "            \"Strategy\": \"Plain\",\n",
      "            \"Partial Mode\": \"Partial\",\n",
      "            \"Parent Relationship\": \"Outer\",\n",
      "            \"Parallel Aware\": false,\n",
      "            \"Async Capable\": false,\n",
      "            \"Startup Cost\": 159309.15,\n",
      "            \"Total Cost\": 159309.16,\n",
      "            \"Plan Rows\": 1,\n",
      "            \"Plan Width\": 8,\n",
      "            \"Plans\": [\n",
      "              {\n",
      "                \"Node Type\": \"Hash Join\",\n",
      "                \"Parent Relationship\": \"Outer\",\n",
      "                \"Parallel Aware\": true,\n",
      "                \"Async Capable\": false,\n",
      "                \"Join Type\": \"Inner\",\n",
      "                \"Startup Cost\": 136024.66,\n",
      "                \"Total Cost\": 159309.09,\n",
      "                \"Plan Rows\": 25,\n",
      "                \"Plan Width\": 4,\n",
      "                \"Inner Unique\": false,\n",
      "                \"Hash Cond\": \"((partsupp.ps_suppkey = supplier.s_suppkey) AND (partsupp.ps_partkey = part.p_partkey))\",\n",
      "                \"Plans\": [\n",
      "                  {\n",
      "                    \"Node Type\": \"Seq Scan\",\n",
      "                    \"Parent Relationship\": \"Outer\",\n",
      "                    \"Parallel Aware\": true,\n",
      "                    \"Async Capable\": false,\n",
      "                    \"Relation Name\": \"partsupp\",\n",
      "                    \"Alias\": \"partsupp\",\n",
      "                    \"Startup Cost\": 0.0,\n",
      "                    \"Total Cost\": 20784.33,\n",
      "                    \"Plan Rows\": 333333,\n",
      "                    \"Plan Width\": 8\n",
      "                  },\n",
      "                  {\n",
      "                    \"Node Type\": \"Hash\",\n",
      "                    \"Parent Relationship\": \"Inner\",\n",
      "                    \"Parallel Aware\": true,\n",
      "                    \"Async Capable\": false,\n",
      "                    \"Startup Cost\": 135084.28,\n",
      "                    \"Total Cost\": 135084.28,\n",
      "                    \"Plan Rows\": 62692,\n",
      "                    \"Plan Width\": 20,\n",
      "                    \"Plans\": [\n",
      "                      {\n",
      "                        \"Node Type\": \"Hash Join\",\n",
      "                        \"Parent Relationship\": \"Outer\",\n",
      "                        \"Parallel Aware\": false,\n",
      "                        \"Async Capable\": false,\n",
      "                        \"Join Type\": \"Inner\",\n",
      "                        \"Startup Cost\": 127306.7,\n",
      "                        \"Total Cost\": 135084.28,\n",
      "                        \"Plan Rows\": 62692,\n",
      "                        \"Plan Width\": 20,\n",
      "                        \"Inner Unique\": false,\n",
      "                        \"Hash Cond\": \"(part.p_partkey = lineitem.l_partkey)\",\n",
      "                        \"Plans\": [\n",
      "                          {\n",
      "                            \"Node Type\": \"Seq Scan\",\n",
      "                            \"Parent Relationship\": \"Outer\",\n",
      "                            \"Parallel Aware\": true,\n",
      "                            \"Async Capable\": false,\n",
      "                            \"Relation Name\": \"part\",\n",
      "                            \"Alias\": \"part\",\n",
      "                            \"Startup Cost\": 0.0,\n",
      "                            \"Total Cost\": 4930.33,\n",
      "                            \"Plan Rows\": 83333,\n",
      "                            \"Plan Width\": 4\n",
      "                          },\n",
      "                          {\n",
      "                            \"Node Type\": \"Hash\",\n",
      "                            \"Parent Relationship\": \"Inner\",\n",
      "                            \"Parallel Aware\": false,\n",
      "                            \"Async Capable\": false,\n",
      "                            \"Startup Cost\": 124690.93,\n",
      "                            \"Total Cost\": 124690.93,\n",
      "                            \"Plan Rows\": 150461,\n",
      "                            \"Plan Width\": 16,\n",
      "                            \"Plans\": [\n",
      "                              {\n",
      "                                \"Node Type\": \"Nested Loop\",\n",
      "                                \"Parent Relationship\": \"Outer\",\n",
      "                                \"Parallel Aware\": false,\n",
      "                                \"Async Capable\": false,\n",
      "                                \"Join Type\": \"Inner\",\n",
      "                                \"Startup Cost\": 1.81,\n",
      "                                \"Total Cost\": 124690.93,\n",
      "                                \"Plan Rows\": 150461,\n",
      "                                \"Plan Width\": 16,\n",
      "                                \"Inner Unique\": false,\n",
      "                                \"Plans\": [\n",
      "                                  {\n",
      "                                    \"Node Type\": \"Nested Loop\",\n",
      "                                    \"Parent Relationship\": \"Outer\",\n",
      "                                    \"Parallel Aware\": false,\n",
      "                                    \"Async Capable\": false,\n",
      "                                    \"Join Type\": \"Inner\",\n",
      "                                    \"Startup Cost\": 1.37,\n",
      "                                    \"Total Cost\": 1247.93,\n",
      "                                    \"Plan Rows\": 2000,\n",
      "                                    \"Plan Width\": 4,\n",
      "                                    \"Inner Unique\": false,\n",
      "                                    \"Join Filter\": \"(nation.n_nationkey = supplier.s_nationkey)\",\n",
      "                                    \"Plans\": [\n",
      "                                      {\n",
      "                                        \"Node Type\": \"Index Scan\",\n",
      "                                        \"Parent Relationship\": \"Outer\",\n",
      "                                        \"Parallel Aware\": false,\n",
      "                                        \"Async Capable\": false,\n",
      "                                        \"Scan Direction\": \"Forward\",\n",
      "                                        \"Index Name\": \"zero_shot_supplier_s_suppkey\",\n",
      "                                        \"Relation Name\": \"supplier\",\n",
      "                                        \"Alias\": \"supplier\",\n",
      "                                        \"Startup Cost\": 0.29,\n",
      "                                        \"Total Cost\": 495.43,\n",
      "                                        \"Plan Rows\": 10000,\n",
      "                                        \"Plan Width\": 8\n",
      "                                      },\n",
      "                                      {\n",
      "                                        \"Node Type\": \"Materialize\",\n",
      "                                        \"Parent Relationship\": \"Inner\",\n",
      "                                        \"Parallel Aware\": false,\n",
      "                                        \"Async Capable\": false,\n",
      "                                        \"Startup Cost\": 1.09,\n",
      "                                        \"Total Cost\": 2.51,\n",
      "                                        \"Plan Rows\": 5,\n",
      "                                        \"Plan Width\": 4,\n",
      "                                        \"Plans\": [\n",
      "                                          {\n",
      "                                            \"Node Type\": \"Hash Join\",\n",
      "                                            \"Parent Relationship\": \"Outer\",\n",
      "                                            \"Parallel Aware\": false,\n",
      "                                            \"Async Capable\": false,\n",
      "                                            \"Join Type\": \"Inner\",\n",
      "                                            \"Startup Cost\": 1.09,\n",
      "                                            \"Total Cost\": 2.48,\n",
      "                                            \"Plan Rows\": 5,\n",
      "                                            \"Plan Width\": 4,\n",
      "                                            \"Inner Unique\": false,\n",
      "                                            \"Hash Cond\": \"(nation.n_regionkey = region.r_regionkey)\",\n",
      "                                            \"Plans\": [\n",
      "                                              {\n",
      "                                                \"Node Type\": \"Seq Scan\",\n",
      "                                                \"Parent Relationship\": \"Outer\",\n",
      "                                                \"Parallel Aware\": false,\n",
      "                                                \"Async Capable\": false,\n",
      "                                                \"Relation Name\": \"nation\",\n",
      "                                                \"Alias\": \"nation\",\n",
      "                                                \"Startup Cost\": 0.0,\n",
      "                                                \"Total Cost\": 1.25,\n",
      "                                                \"Plan Rows\": 25,\n",
      "                                                \"Plan Width\": 8\n",
      "                                              },\n",
      "                                              {\n",
      "                                                \"Node Type\": \"Hash\",\n",
      "                                                \"Parent Relationship\": \"Inner\",\n",
      "                                                \"Parallel Aware\": false,\n",
      "                                                \"Async Capable\": false,\n",
      "                                                \"Startup Cost\": 1.07,\n",
      "                                                \"Total Cost\": 1.07,\n",
      "                                                \"Plan Rows\": 1,\n",
      "                                                \"Plan Width\": 4,\n",
      "                                                \"Plans\": [\n",
      "                                                  {\n",
      "                                                    \"Node Type\": \"Seq Scan\",\n",
      "                                                    \"Parent Relationship\": \"Outer\",\n",
      "                                                    \"Parallel Aware\": false,\n",
      "                                                    \"Async Capable\": false,\n",
      "                                                    \"Relation Name\": \"region\",\n",
      "                                                    \"Alias\": \"region\",\n",
      "                                                    \"Startup Cost\": 0.0,\n",
      "                                                    \"Total Cost\": 1.07,\n",
      "                                                    \"Plan Rows\": 1,\n",
      "                                                    \"Plan Width\": 4,\n",
      "                                                    \"Filter\": \"((r_regionkey <> 2) AND ((r_comment)::text = 'uickly special accounts cajole carefully blithely close requests. carefully final asymptotes haggle furiousl'::text))\"\n",
      "                                                  }\n",
      "                                                ]\n",
      "                                              }\n",
      "                                            ]\n",
      "                                          }\n",
      "                                        ]\n",
      "                                      }\n",
      "                                    ]\n",
      "                                  },\n",
      "                                  {\n",
      "                                    \"Node Type\": \"Index Scan\",\n",
      "                                    \"Parent Relationship\": \"Inner\",\n",
      "                                    \"Parallel Aware\": false,\n",
      "                                    \"Async Capable\": false,\n",
      "                                    \"Scan Direction\": \"Forward\",\n",
      "                                    \"Index Name\": \"zero_shot_lineitem_l_suppkey\",\n",
      "                                    \"Relation Name\": \"lineitem\",\n",
      "                                    \"Alias\": \"lineitem\",\n",
      "                                    \"Startup Cost\": 0.43,\n",
      "                                    \"Total Cost\": 60.97,\n",
      "                                    \"Plan Rows\": 75,\n",
      "                                    \"Plan Width\": 12,\n",
      "                                    \"Index Cond\": \"(l_suppkey = supplier.s_suppkey)\",\n",
      "                                    \"Filter\": \"((l_shipinstruct = 'COLLECT COD'::bpchar) AND (l_returnflag = 'N'::bpchar))\"\n",
      "                                  }\n",
      "                                ]\n",
      "                              }\n",
      "                            ]\n",
      "                          }\n",
      "                        ]\n",
      "                      }\n",
      "                    ]\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"peakmem\": 18112\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_plans(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        plans = json.load(f)\n",
    "    return plans\n",
    "\n",
    "# Load a sample plan\n",
    "sample_plans = load_plans('plans.json')  # Replace with your actual file path\n",
    "\n",
    "# Inspect the first plan\n",
    "print(json.dumps(sample_plans[0], indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zsce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
